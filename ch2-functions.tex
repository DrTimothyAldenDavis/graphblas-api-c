% This is ch2-functions.tex of the GraphBLAS specification.
% This is an included file. See the master file for more information.
%

%

\chapter{Mathematics}
\index{mathematics}
\label{chap:mathematics}
\section{Introduction}
This chapter describes the mathematics in the GraphBLAS standard.  The GraphBLAS define a narrow set of mathematical operations that have been found to be useful for implementing a wide range of graph operations.  At the heart of the GraphBLAS are 2D mathematical objects called matrices.  The matrices are usually sparse, which implies that the majority of the elements in the matrix are zero and are often not stored to make their implementation more efficient.  Sparsity is independent of the GraphBLAS mathematics.  All the mathematics defined in the GraphBLAS will work regardless of whether the underlying matrix is sparse or dense.

Graphs represent connections between vertices with edges.  Matrices can represent a wide range of graphs using \emph{adjacency} matrices or \emph{incidence} matrices.  Adjacency matrices are often easier to analyze while incidence matrices are often better for representing data.  Fortunately, the two are easily connected by the fundamental mathematical operation of the GraphBLAS: matrix-matrix multiply.  One of the great features of the GraphBLAS mathematics is that no matter what kind of graph or matrix is being use, the core operations remain the same.  In other words, a very small number of matrix operations can be used manipulate a very wide range of graphs.

The mathematics of the GraphBLAS will be described using a ``center outward'' approach.  Initially, the most important specific cases will be described that are a the center of GraphBLAS.  The conditions on these cases will then be relaxed to the arrive at more general definition.  This approach has the advantage of being more easily understandable and describing the most important cases first.

\subsection{Adjacency Matrix}
Given an adjacency matrix $\mathbf{A}$, if $\mathbf{A}(v_1,v_2) = 1$, then there exists an edge going from vertex $v_1$ to vertex $v_2$.  Likewise, if $\mathbf{A}(v_1,v_2) = 0$, then there is no edge between $v_1$ and $v_2$.  Adjacency matrices have direction, which means that $\mathbf{A}(v_1,v_2)$ is not the same as $\mathbf{A}(v_2,v_1)$.  Adjacency matrices can also have edge weights.  If $\mathbf{A}(v_1,v_2) = w_{ij}$, and $w_{ij} \neq 0$, then the edge going from $v_1$ to $v_2$ is said to have weight $w_{ij}$.  Adjacency matrices provide a simple way to represent the connections between vertices in a graph between one set of vertices and another.  Adjacency matrices are often square and both out-vertices (rows) and the in-vertices (columns) are the same set of vertices.  Adjacency matrices can be rectangular in which case the out-vertices (rows) and the in-vertices (columns) are different sets of vertices.  Such graphs are often called bipartite graphs.  In summary, adjacency matrices can represent a wide range of graphs, which include any graph with any set of the following properties: directed, weighted, and/or bipartite.

\subsection{Incidence Matrix}
An incidence, or edge matrix $\mathbf{E}$, uses the rows to represent every edge in the graph and the columns represent every vertex.  There are a number of conventions for denoting an edge in an incidence matrix.  One such convention is to set $\mathbf{E}(i,v_1) = -1$ and $\mathbf{E}(i,v_2) = 1$ to indicate that edge $i$ is a connection from $v_1$ to $v_2$.  Incidence matrices are useful because they can easily represent multi-graphs, hyper-graphs, and multi-partite graphs.  These complex graphs are difficult to capture with an adjacency matrix.  A multi-graph has multiple edges between the same vertices.  If there was another edge, $j$, from $v_1$ to $v_2$, this can be captured in an incidence matrix by setting $\mathbf{E}(j,v_1) = -1$ and $\mathbf{E}(j,v_2) = 1$.  In a hyper-graph, one edge can go between more than two vertices.  For example, to denote edge $i$ has a connection from $v_1$ to $v_2$ and $v_3$ can be accomplished by also setting $\mathbf{E}(i,v_3) = 1$.  Furthermore, $v_1$, $v_2$, and $v_3$ can be drawn from  different classes of vertices and so $\mathbf{E}$ can be used to represent multi-partite graphs.  Thus, an incidence matrix can be used to represent a graph with any set of the following graph properties: directed, weighted, multi-partite, multi-edge, and/or hyper-edge.

\section{Matrix Definition}
  The canonical matrix of the GraphBLAS has $N$ rows and $M$ columns of real numbers.  Such a matrix can be denoted as
$$
  \mathbf{A}: \mathbb{R}^{N \times M}
$$
The canonical row and and column indexes of the matrix $\mathbf{A}$ are $i \in I = \{1,\ldots,N\}$ and $j \in J = \{1,\ldots,M\}$, so that any particular value $\mathbf{A}$ can be denoted as $\mathbf{A}(i,j)$.  [Note: a specific GraphBLAS \emph{implementation} might use IEEE 64 bit double precision floating point numbers to represent real numbers, 64 bit unsigned integers to represent row and column indices, and the compressed sparse rows (CSR) format or the compressed sparse columns (CSC) format to store the non-zero values inside the matrix.]

  A matrix of complex numbers is denoted
$$
  \mathbf{A}: \mathbb{C}^{N \times M}
$$
  A matrix of integers $\{\ldots, -1, 0, 1, \ldots\}$ is denoted
$$
  \mathbf{A}: \mathbb{Z}^{N \times M}
$$
  A matrix of natural numbers $\{1, 2, 3, \ldots\}$ is denoted
$$
  \mathbf{A}: \mathbb{N}^{N \times M}
$$

  Canonical row and column indices are natural numbers $I,J : \mathbb{N}$.  In some GraphBLAS implementations these indices could be positive integers  $I = \{0,\ldots,N-1\}$ and $J = \{0,\ldots,M-1\}$.
  
  For the GraphBLAS a matrix is defined as the following 2D mapping
$$
  \mathbf{A} : I \times J \rightarrow \mathbb{S}
$$
where the indices $I, J : \mathbb{Z}$ are finite sets of integers with with $N$ and $M$ elements respectively, and  $\mathbb{S} \in \{\mathbb{R},\mathbb{Z},\mathbb{N}, \ldots \}$ is a set of scalars.  Without loss of generality matrices can be denoted
$$
  \mathbf{A}: \mathbb{S}^{N \times M}
$$

If the internal storage format of the matrix needs to be indicated, this can be done by
$$
  \mathbf{A}: \mathbb{S}^{N \times M}_{\rm CSC}  ~~~~~~~~ {\rm or}  ~~~~~~~~ 
  \mathbf{A}: \mathbb{S}^{N \times M}_{\rm CSR}
$$

  A \emph{vector} is a matrix where either $N=1$ or $M=1$. A column vector is denoted
$$
 \mathbf{v} = \mathbb{S}^{N \times 1}
$$
  A row vector is denoted
$$
  \mathbf{v} = \mathbb{S}^{1 \times M}
$$

  A scalar is a single element of a set $s \in \mathbb{S}$ and has no matrix dimensions.
%However, in certain implementation contexts it can sometimes be convenient to allow a single element vector/matrix $s : \mathbb{S}^{1 \times 1}$ to have scalar properties.

\section{Scalar Operations}
  The GraphBLAS matrix operations are built on top of scalar operations.  The primary scalar operations are standard arithmetic addition (e.g., $1 + 1 = 2$) and multiplication (e.g., $2 \times 2 = 4$).  The GraphBLAS also allow these scalar operations of addition and multiplication to be defined by the implementation or the user.  To prevent confusion with standard addition and multiplication, $\oplus$ will be used to denote scalar addition and $\otimes$ will be use to denote scalar multiplication.  In this notation, standard arithmetic addition and arithmetic multiplication of real numbers $a, b, c \in \mathbb{R}$, where $\oplus \equiv +$ and $\oplus \equiv \times$ results in
$$
   c = a \oplus b  ~~~~~~~~~ \Rightarrow ~~~~~~~~~ c = a + b
$$
and
$$
   c = a \otimes b  ~~~~~~~~~ \Rightarrow ~~~~~~~~~ c = a \times b
$$

  Allowing $\oplus$ and $\otimes$ to be implementation (or user) defined functions enables the GraphBLAS to succinctly implement a wide range of algorithms on scalars of all different types (not just real numbers).  Certain $\oplus$ and $\otimes$ combinations  over certain sets of scalars are particular useful because they preserve desirable mathematical properties such as commutativity
$$
 a \oplus b = b \oplus a ~~~~~~~~~ ~~~~~~~~~ a \otimes b = b \otimes a
$$
associativity
$$
 (a \oplus b) \oplus c = a \oplus (b \oplus c) ~~~~~~~~~ ~~~~~~~~~ (a \otimes b) \oplus c = a \oplus (b \otimes c)
$$
and distributivity
$$
 a \otimes (b \oplus c)  = (a \otimes b) \oplus (a \otimes c)
$$

  In most cases, if these properties are true for scalar operations they will also be true for their corresponding matrix operations.  Commutativity, associativity, and distributivity are {\emph extremely} useful properties for building graph applications because they allow the builder to swap operations without changing the result.

  Example combinations of $\oplus$ and $\otimes$ that preserve scalar commutativity, associativity, and distributivity include (but are not limited to) standard arithmetic
$$
  \oplus \equiv + ~~~~~~~~~ \otimes \equiv \times ~~~~~~~~~ a, b, c \in \mathbb{R}
$$
max-plus algebras
$$
  \oplus \equiv \max ~~~~~~~~~ \otimes \equiv + ~~~~~~~~~ a, b, c \in \{-\infty \cup \mathbb{R}\}
$$
min-max algebras
$$
  \oplus \equiv \max ~~~~~~~~~ \otimes \equiv \min ~~~~~~~~~ a, b, c \in [0,\infty)
$$
and power set algebras
$$
  \oplus \equiv \cup ~~~~~~~~~ \otimes \equiv \cap ~~~~~~~~~ a, b, c \subset \mathbb{Z}
$$

  Other functions can also be defined for $\oplus$ and $\otimes$ that do not preserve the above properties.  For example, it is often useful for $\oplus$ or $\otimes$ to pull in other data such as vertex labels of a graph. 
  
\section{0-Element}
  Sparse matrices play an important role in GraphBLAS.  Many implementations of sparse matrices reduce storage by not storing the 0 valued elements in the matrix.  In most cases, the 0 element is standard arithmetic 0.  The GraphBLAS also allows the 0 element to be defined by the implementation or user.  This can be particularly helpful when combined with user defined $\oplus$ and $\otimes$ operations.  Specifically, if the 0 element has certain properties with respect scaler $\oplus$ and $\otimes$ then sparsity of matrix operations can be managed efficiently.  These properties are the additive identity
$$
     a \oplus 0 = a
$$
and the multiplicative annihilator
$$
     a \otimes 0 = 0
$$

\section{Matrix Operations}


For my own reference, I'm leaving in a few latex fragments I'd llike to remember for when we add our own text.


\begin{boxedcode}
\#pragma\plc{ }omp\plc{ directive-name [clause[ [},\plc{] clause] ... ] new-line}
\end{boxedcode}

As an example of how a construct might look, here is the single construct from OpenMP

\subsection{\code{single} Construct}
\index{single@{\code{single}}}
\index{constructs!single@{\code{single}}}
\label{subsec:single Construct}
\summary
The \code{single} construct specifies that the associated structured block is executed by only 
one of the threads in the team (not necessarily the master thread), in the context of its 
implicit task. The other threads in the team, which do not execute the block, wait at an 
implicit barrier at the end of the \code{single} construct unless a \code{nowait} clause is specified.

\parbox{\linewidth}{%
\syntax
\ccppspecificstart}
The syntax of the single construct is as follows:

\begin{boxedcode}
\#pragma omp single \plc{[clause[ [},\plc{] clause] ... ] new-line}
   \plc{structured-block}
\end{boxedcode}

\begin{samepage}
where \plc{clause} is one of the following:

\begin{indentedcodelist}
private(\plc{list})
firstprivate(\plc{list})
copyprivate(\plc{list})
nowait
\end{indentedcodelist}
\ccppspecificend
\end{samepage}

\fortranspecificstart
The syntax of the \code{single} construct is as follows:

\begin{boxedcode}
!\$omp single \plc{[clause[ [},\plc{] clause] ... ]}
   \plc{structured-block} 
!\$omp end single \plc{[end\_clause[ [},\plc{] end\_clause] ... ]}
\end{boxedcode}

where \plc{clause} is one of the following:

\begin{indentedcodelist}
private(\plc{list})
firstprivate(\plc{list})
\end{indentedcodelist}

and \plc{end\_clause} is one of the following: 

\begin{indentedcodelist}
copyprivate(\plc{list})
nowait
\end{indentedcodelist}
\fortranspecificend

\binding
The binding thread set for a \code{single} region is the current team. A \code{single} region 
binds to the innermost enclosing \code{parallel} region. Only the threads of the team 
executing the binding \code{parallel} region participate in the execution of the structured 
block and the implied barrier of the \code{single} region if the barrier is not eliminated by a 
\code{nowait} clause.

\descr
The method of choosing a thread to execute the structured block is implementation 
defined. There is an implicit barrier at the end of the \code{single} construct unless a 
\code{nowait} clause is specified. 

\restrictions
Restrictions to the \code{single} construct are as follows: 

\begin{itemize}
\item The \code{copyprivate} clause must not be used with the \code{nowait} clause.

\item At most one \code{nowait} clause can appear on a \code{single} construct.

\cppspecificstart
\item A throw executed inside a \code{single} region must cause execution to resume within the 
same \code{single} region, and the same thread that threw the exception must catch it.
\cppspecificend
\end{itemize}


\crossreferences
\begin{itemize}
\item \code{private} and \code{firstprivate} clauses, see 
\specref{subsec:Data-Sharing Attribute Clauses}.

\item \code{copyprivate} clause, see 
\specref{subsubsec:copyprivate clause}.
\end{itemize}


% This is the end of ch2-functions.tex of the GraphBLAS specification.

